{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc704319",
   "metadata": {},
   "source": [
    "We are interesting in a system that could classify crime discription into different categories. We want to create a system that could automatically assign a described crime to category which could help law enforcements to assign right officers to crime or could automatically assign officers to crime based on the classification.\n",
    "\n",
    "We are using dataset from Kaggle on San Francisco Crime. Our responsibilty is to train a model based on 39 pre-defined categories, test the model accuracy \n",
    "\n",
    "To solve this problem, we will use a variety of feature extraction techniques along with different supervised machine learning algorithms in Pyspark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5ae04",
   "metadata": {},
   "source": [
    "## Setup Spark and load other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"crimeClass\").getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c56558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.random.seed(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5e2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82c4e3",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14e5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('train/train.csv', inferSchema=True, header=True, timestampFormat='yyyy-mm-dd hh mm ss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36ae8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Dates='2015-05-13 23:53:00', Category='WARRANTS', Descript='WARRANT ARREST', DayOfWeek='Wednesday', PdDistrict='NORTHERN', Resolution='ARREST, BOOKED', Address='OAK ST / LAGUNA ST', X=-122.425891675136, Y=37.7745985956747)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0ed032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
      "|              Dates|      Category|            Descript|DayOfWeek|PdDistrict|    Resolution|             Address|                  X|                 Y|\n",
      "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
      "|2015-05-13 23:53:00|      WARRANTS|      WARRANT ARREST|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
      "|2015-05-13 23:53:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|  OAK ST / LAGUNA ST|  -122.425891675136|  37.7745985956747|\n",
      "|2015-05-13 23:33:00|OTHER OFFENSES|TRAFFIC VIOLATION...|Wednesday|  NORTHERN|ARREST, BOOKED|VANNESS AV / GREE...|   -122.42436302145|  37.8004143219856|\n",
      "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  NORTHERN|          NONE|1500 Block of LOM...|-122.42699532676599| 37.80087263276921|\n",
      "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|      PARK|          NONE|100 Block of BROD...|  -122.438737622757|37.771541172057795|\n",
      "|2015-05-13 23:30:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday| INGLESIDE|          NONE| 0 Block of TEDDY AV|-122.40325236121201|   37.713430704116|\n",
      "|2015-05-13 23:30:00| VEHICLE THEFT|   STOLEN AUTOMOBILE|Wednesday| INGLESIDE|          NONE| AVALON AV / PERU AV|  -122.423326976668|  37.7251380403778|\n",
      "|2015-05-13 23:30:00| VEHICLE THEFT|   STOLEN AUTOMOBILE|Wednesday|   BAYVIEW|          NONE|KIRKWOOD AV / DON...|  -122.371274317441|  37.7275640719518|\n",
      "|2015-05-13 23:00:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  RICHMOND|          NONE|600 Block of 47TH AV|  -122.508194031117|37.776601260681204|\n",
      "|2015-05-13 23:00:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|   CENTRAL|          NONE|JEFFERSON ST / LE...|  -122.419087676747|  37.8078015516515|\n",
      "|2015-05-13 22:58:00| LARCENY/THEFT|PETTY THEFT FROM ...|Wednesday|   CENTRAL|          NONE|JEFFERSON ST / LE...|  -122.419087676747|  37.8078015516515|\n",
      "|2015-05-13 22:30:00|OTHER OFFENSES|MISCELLANEOUS INV...|Wednesday|   TARAVAL|          NONE|0 Block of ESCOLT...|  -122.487983072777|37.737666654332706|\n",
      "|2015-05-13 22:30:00|     VANDALISM|MALICIOUS MISCHIE...|Wednesday|TENDERLOIN|          NONE|  TURK ST / JONES ST|-122.41241426358101|  37.7830037964534|\n",
      "|2015-05-13 22:06:00| LARCENY/THEFT|GRAND THEFT FROM ...|Wednesday|  NORTHERN|          NONE|FILLMORE ST / GEA...|  -122.432914603494|  37.7843533426568|\n",
      "|2015-05-13 22:00:00|  NON-CRIMINAL|      FOUND PROPERTY|Wednesday|   BAYVIEW|          NONE|200 Block of WILL...|  -122.397744427103|  37.7299346936044|\n",
      "|2015-05-13 22:00:00|  NON-CRIMINAL|      FOUND PROPERTY|Wednesday|   BAYVIEW|          NONE|0 Block of MENDEL...|-122.38369150395901|  37.7431890419965|\n",
      "|2015-05-13 22:00:00|       ROBBERY|ROBBERY, ARMED WI...|Wednesday|TENDERLOIN|          NONE|  EDDY ST / JONES ST|  -122.412597377187|37.783932027727296|\n",
      "|2015-05-13 21:55:00|       ASSAULT|AGGRAVATED ASSAUL...|Wednesday| INGLESIDE|          NONE|GODEUS ST / MISSI...|  -122.421681531572|  37.7428222004845|\n",
      "|2015-05-13 21:40:00|OTHER OFFENSES|   TRAFFIC VIOLATION|Wednesday|   BAYVIEW|ARREST, BOOKED|MENDELL ST / HUDS...|-122.38640086995301|   37.738983491072|\n",
      "|2015-05-13 21:30:00|  NON-CRIMINAL|      FOUND PROPERTY|Wednesday|TENDERLOIN|          NONE|100 Block of JONE...|  -122.412249767634|   37.782556330202|\n",
      "+-------------------+--------------+--------------------+---------+----------+--------------+--------------------+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9d6c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Dates: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Descript: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- PdDistrict: string (nullable = true)\n",
      " |-- Resolution: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- X: double (nullable = true)\n",
      " |-- Y: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f214b5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------+\n",
      "|Category      |Descript                                 |\n",
      "+--------------+-----------------------------------------+\n",
      "|WARRANTS      |WARRANT ARREST                           |\n",
      "|OTHER OFFENSES|TRAFFIC VIOLATION ARREST                 |\n",
      "|OTHER OFFENSES|TRAFFIC VIOLATION ARREST                 |\n",
      "|LARCENY/THEFT |GRAND THEFT FROM LOCKED AUTO             |\n",
      "|LARCENY/THEFT |GRAND THEFT FROM LOCKED AUTO             |\n",
      "|LARCENY/THEFT |GRAND THEFT FROM UNLOCKED AUTO           |\n",
      "|VEHICLE THEFT |STOLEN AUTOMOBILE                        |\n",
      "|VEHICLE THEFT |STOLEN AUTOMOBILE                        |\n",
      "|LARCENY/THEFT |GRAND THEFT FROM LOCKED AUTO             |\n",
      "|LARCENY/THEFT |GRAND THEFT FROM LOCKED AUTO             |\n",
      "|LARCENY/THEFT |PETTY THEFT FROM LOCKED AUTO             |\n",
      "|OTHER OFFENSES|MISCELLANEOUS INVESTIGATION              |\n",
      "|VANDALISM     |MALICIOUS MISCHIEF, VANDALISM OF VEHICLES|\n",
      "|LARCENY/THEFT |GRAND THEFT FROM LOCKED AUTO             |\n",
      "|NON-CRIMINAL  |FOUND PROPERTY                           |\n",
      "|NON-CRIMINAL  |FOUND PROPERTY                           |\n",
      "|ROBBERY       |ROBBERY, ARMED WITH A KNIFE              |\n",
      "|ASSAULT       |AGGRAVATED ASSAULT WITH BODILY FORCE     |\n",
      "|OTHER OFFENSES|TRAFFIC VIOLATION                        |\n",
      "|NON-CRIMINAL  |FOUND PROPERTY                           |\n",
      "+--------------+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Category', 'Descript').show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6537e7",
   "metadata": {},
   "source": [
    "We can see Descirpt coulmn gives some idea on how can we classify the crimes in different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eec7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting both coulmns data to lower case\n",
    "new_data = data.select(lower(col('Category')), lower(col('Descript')))\n",
    "new_data = new_data.withColumnRenamed('lower(Category)', 'Category').withColumnRenamed('lower(Descript)', 'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1287b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|      Category|         Description|\n",
      "+--------------+--------------------+\n",
      "|      warrants|      warrant arrest|\n",
      "|other offenses|traffic violation...|\n",
      "|other offenses|traffic violation...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| vehicle theft|   stolen automobile|\n",
      "| vehicle theft|   stolen automobile|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "| larceny/theft|petty theft from ...|\n",
      "|other offenses|miscellaneous inv...|\n",
      "|     vandalism|malicious mischie...|\n",
      "| larceny/theft|grand theft from ...|\n",
      "|  non-criminal|      found property|\n",
      "|  non-criminal|      found property|\n",
      "|       robbery|robbery, armed wi...|\n",
      "|       assault|aggravated assaul...|\n",
      "|other offenses|   traffic violation|\n",
      "|  non-criminal|      found property|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3346e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4515ea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878049"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25cbd4",
   "metadata": {},
   "source": [
    "There are total 878049 records in train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fc83e",
   "metadata": {},
   "source": [
    "To familiar ourselves with the dataset, we need to see the top list of the crime categories and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc73bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of unique categories in given crime data\n",
    "new_data.select('Category').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f5c9de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|      Category| count|\n",
      "+--------------+------+\n",
      "| larceny/theft|174900|\n",
      "|other offenses|126182|\n",
      "|  non-criminal| 92304|\n",
      "|       assault| 76876|\n",
      "| drug/narcotic| 53971|\n",
      "| vehicle theft| 53781|\n",
      "|     vandalism| 44725|\n",
      "|      warrants| 42214|\n",
      "|      burglary| 36755|\n",
      "|suspicious occ| 31414|\n",
      "+--------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#top 10 categories present in data \n",
    "new_data.groupBy('Category').count().orderBy(col('count').desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c58f9566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of unique Description in given crime data\n",
    "new_data.select('Description').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b3cba80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|         Description|count|\n",
      "+--------------------+-----+\n",
      "|grand theft from ...|60022|\n",
      "|       lost property|31729|\n",
      "|             battery|27441|\n",
      "|   stolen automobile|26897|\n",
      "|drivers license, ...|26839|\n",
      "|      warrant arrest|23754|\n",
      "|suspicious occurr...|21891|\n",
      "|aided case, menta...|21497|\n",
      "|petty theft from ...|19771|\n",
      "|malicious mischie...|17789|\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#top 10 Descriptions present in data \n",
    "new_data.groupBy('Description').count().orderBy(col('count').desc()).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065359d",
   "metadata": {},
   "source": [
    "**Category feature will be our label (multi-class).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648ba41",
   "metadata": {},
   "source": [
    "## Splitting the dataset into Training and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89baa8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count -  614457\n",
      "Test data count -  263592\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = new_data.randomSplit([0.7,0.3], seed = 60)\n",
    "print('Train data count - ', train_data.count())\n",
    "print('Test data count - ', test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3dc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (RegexTokenizer, StopWordsRemover, CountVectorizer, OneHotEncoder, StringIndexer, \n",
    "                               VectorAssembler, HashingTF, IDF, Word2Vec)\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd55d25",
   "metadata": {},
   "source": [
    "We are using above imported NLP features to work with text data (Description Column). As ML understand the number we have to convert the text data into number which machine can understand\n",
    "\n",
    "Process : \n",
    "-  Description in text -> Tokens -> stop_word_remove -> count_vector/TF-IDF -> Description in number\n",
    "- for eg.\n",
    "-  I am a Boy, play cricket -> I, am, a, boy -> boy, cricket -> (1,1) -> [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06f77363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer with regextokenizer()\n",
    "regex_tokenizer = RegexTokenizer(pattern='\\\\W')\\\n",
    "                  .setInputCol(\"Description\")\\\n",
    "                  .setOutputCol(\"tokens\")\n",
    "\n",
    "#stopwords with stopwordsremover()\n",
    "extra_stopwords = ['http','amp','rt','t','c','the']\n",
    "stopwords_remover = StopWordsRemover()\\\n",
    "                    .setInputCol('tokens')\\\n",
    "                    .setOutputCol('filtered_words')\\\n",
    "                    .setStopWords(extra_stopwords)\n",
    "                    \n",
    "\n",
    "#bags of words using countVectorizer()\n",
    "count_vectors = CountVectorizer(vocabSize=10000, minDF=5)\\\n",
    "               .setInputCol(\"filtered_words\")\\\n",
    "               .setOutputCol(\"features\")\n",
    "\n",
    "\n",
    "#TF-IDF to vectorise features instead of countVectoriser\n",
    "hashingTf = HashingTF(numFeatures=10000)\\\n",
    "            .setInputCol(\"filtered_words\")\\\n",
    "            .setOutputCol(\"raw_features\")\n",
    "            \n",
    "#minDocFreq to remove sparse terms\n",
    "idf = IDF(minDocFreq=5)\\\n",
    "        .setInputCol(\"raw_features\")\\\n",
    "        .setOutputCol(\"features\")\n",
    "\n",
    "#bag of words using Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=1000, minCount=0)\\\n",
    "           .setInputCol(\"filtered_words\")\\\n",
    "           .setOutputCol(\"features\")\n",
    "\n",
    "#Encode the Category variable into label using StringIndexer\n",
    "label_string_idx = StringIndexer()\\\n",
    "                  .setInputCol(\"Category\")\\\n",
    "                  .setOutputCol(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd0994",
   "metadata": {},
   "source": [
    "We are using all these features in building pipelines forour model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf14d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic Regression classifier\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "#Naive Bayes classifier\n",
    "nb = NaiveBayes(smoothing=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1b979",
   "metadata": {},
   "source": [
    "### Logistic Regression with Count Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527f0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, lr])\n",
    "model_cv_lr = pipeline_cv_lr.fit(train_data)\n",
    "predictions_cv_lr = model_cv_lr.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dd95375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "|         Description|     Category|         probability|label|prediction|\n",
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "|theft, bicycle, <...|larceny/theft|[0.87175291843817...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.87175291843817...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.87175291843817...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.87175291843817...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.87175291843817...|  0.0|       0.0|\n",
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_cv_lr.select('Description','Category',\"probability\",\"label\",\"prediction\").orderBy(\"probability\", \n",
    "                                                                                              ascending=False).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a8a4731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9723579882349168\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
    "evaluator_cv_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_lr)\n",
    "print('Accuracy : ', evaluator_cv_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15856989",
   "metadata": {},
   "source": [
    "### Naive Bayes with Count Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfcf6ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,count_vectors,label_string_idx, nb])\n",
    "model_cv_nb = pipeline_cv_nb.fit(train_data)\n",
    "predictions_cv_nb = model_cv_nb.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ba6fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9935325400900984\n"
     ]
    }
   ],
   "source": [
    "evaluator_cv_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_cv_nb)\n",
    "print('Accuracy : ', evaluator_cv_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63883f28",
   "metadata": {},
   "source": [
    "### Logistic Regression Using TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "269139b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_idf_lr = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, lr])\n",
    "model_idf_lr = pipeline_idf_lr.fit(train_data)\n",
    "predictions_idf_lr = model_idf_lr.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4e03ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "|         Description|     Category|         probability|label|prediction|\n",
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "|theft, bicycle, <...|larceny/theft|[0.88418347520914...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.88418347520914...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.88418347520914...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.88418347520914...|  0.0|       0.0|\n",
      "|theft, bicycle, <...|larceny/theft|[0.88418347520914...|  0.0|       0.0|\n",
      "+--------------------+-------------+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_idf_lr.select('Description','Category',\"probability\",\n",
    "                          \"label\",\"prediction\").orderBy(\"probability\",ascending=False).show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b45fd4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.972293366901647\n"
     ]
    }
   ],
   "source": [
    "evaluator_idf_lr = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_lr)\n",
    "print('Accuracy : ', evaluator_idf_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fffeb7",
   "metadata": {},
   "source": [
    "### Naive Bayes with TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e7aac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_idf_nb = Pipeline().setStages([regex_tokenizer,stopwords_remover,hashingTf, idf, label_string_idx, nb])\n",
    "model_idf_nb = pipeline_idf_nb.fit(train_data)\n",
    "predictions_idf_nb = model_idf_nb.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85d92c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.9949302190940209\n"
     ]
    }
   ],
   "source": [
    "evaluator_idf_nb = MulticlassClassificationEvaluator().setPredictionCol(\"prediction\").evaluate(predictions_idf_nb)\n",
    "print('Accuracy : ', evaluator_idf_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18221e55",
   "metadata": {},
   "source": [
    "As you can see, TF-IDF proves to be best vectoriser for this dataset, while Naive Bayes proves to be better algorithm for text analysis than Logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951d4d9",
   "metadata": {},
   "source": [
    "Link - https://github.com/aakinlalu/Crime-Classification-using-PySpark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e49f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
